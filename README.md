# Microsoft Malware Prediction
kaggleの「Microsoft Malware Prediction」参加後の振り返り    

### 内容
2018年12月〜2019年3月の間にkaggleで開催されていた「Microsoft Malware Prediction」のコンペに参加しました。  
初めて予測スコアの提出まで行い、多くの学びがあったので  
作成したコード、上位ランカーのコードと自分のコードの比較、今後の課題をまとめました。    

### コンペ概要
Microsoftが提供するPCのデータを元に、テストデータとして与えられるPCが  
すぐにマルウェアに感染するか否かを予測するコンペ（二値分類）。  
- **訓練データ件数**  
  8,921,483件  
- **テストデータ件数**  
  7,853,253件  
- **データセットのID**  
  MachineIdentifier列  
- **データセットのラベル（目的変数）**  
  HasDetections列  
  マルウェアが検出されていない=0、マルウェアが検出された=1  
- **評価指標**  
  AUC    

データの詳細は以下リンクのData Description欄を参照。  
<https://www.kaggle.com/c/microsoft-malware-prediction/data>    

### 結果  
2002 / 2426でした。  
まだまだ学ぶことが多そうです。順位の詳細は下記リンクを参照  
<https://www.kaggle.com/takafumif/competitions>  


### 作成したコード    
作成したコードは、同フォルダのmalware_prediction.ipynbファイル内に記載しています。  
<https://github.com/takafumi-7/Microsoft-Malware-Prediction/blob/master/malware_prediction.ipynb>

大まかな流れとして、以下の順で処理するコードを作成しました。
1. 前処理に用いる情報を作成
（以下を50万件ずつ繰り返す）
2. 訓練データを前処理
3. 訓練データをモデルにfit
4. テストデータを前処理
5. テストデータをpredict  

以下にそれぞれの工程で試みたことを詳しく記載します。    


##### 1. 前処理に用いる情報を作成　　
以下四点を実施する
- One Hot EncodingとTarget Encodingそれぞれの対象のカテゴリ変数を選定  
  一意の値が10個以下のカテゴリ変数はOne Hot Encoding対象、それ以外はTarget Encoding対象とした。  
  （pandasのDataFrameを扱う場合、カーディナリティの高いカラムにOne Hot Encodingを適用すると  
  カラム数が増えすぎメモリ効率に支障をきたすため）
- 訓練データ全体に、対象のカテゴリ変数に対してOne Hot Encodingを施した場合のカラム構造を作成  
  実際に前処理を施す時点では50万件ずつ処理することになるので、  
  その時点では全体のカラム構造はわからない⇨前処理前に作成する
- Target Encodingに用いる各カラムの値と変換後の値の対応を保有するdictionaryを作成  
 pandasのDataFrameで全8,921,483件の訓練データを用いてTarget Encodingの変換値を計算するのは計算負荷が高くなるため、
 各カラムの各値の個数とその値の行の中でmalwareが検出された（HasDetectionsが1である）行数をDBでテーブルとして作成し、  
 csvファイルとして出力する。DBにはPostgreSQLを使用。  
 （イメージ図）  

| カラム名    | 値    | 全体の個数     | HasDetectionsが1である個数 |
|:--------:|:-----------:|:------------:|:-------------------------:|
| ProductName | fep   | 7    |  3                |
| ProductName | mse | 94873       |  45,961                    |
| ProductName | win8defender | 8,826,520       |  4,412,891                    |
| DefaultBrowsersIdentifier | 2032 | 37       |  25                    |
| DefaultBrowsersIdentifier | 2064 | 13,990       |  5948                    |
| SmartScreen | Block | 22,533      |  11,698                    |

出力したcsvファイルをPythonでDataFrameとして読み込み、各カラムの各値におけるmalware検出率の変換値を計算して  
{カラム名：{値1：変換後の値1, 値2：変換後の値2, …}, …}のディクショナリを作成し、それをtarget encodingに使用する。  
また、malware検出率の計算において個数が極端に少ない値などは正しく確率を算出できていない可能性が高いため、  
 「smoothing」を施す。（計算式は下記リンク「smoothing」欄を参照）  
 <https://qiita.com/suaaa7/items/cfe9a9e516b5b784570f>  
 - 前処理後の各カラムの平均値を計算し、dictionaryとして保有  
   One Hot Encoding後のカラム構造を予め取得しておくのと同じ理由で、事前に平均値を算出する。
   平均値を計算するには訓練データに全前処理を施し、全て数値変数にすることが必要なので、  
   以下の順番で処理をする。
   1. 訓練データを50万件ずつ上記までの前処理を施し、各カラムの50万件ごとの合計値を算出
   2. 訓練データ全件に対して1を実施し、各カラムの全件の合計値を算出
   3. 各カラムの合計値をそれぞれ全行数の8,921,483で除算し、平均値を算出    
   


#### 2. 訓練データを前処理  
今回作成したコードの前処理の流れを細分化すると、以下のようになります。  
**特徴量の追加・削除**  
⇩  
**カラムごとの固有の処理**  
⇩  
**カテゴリカル変数を数値化**  
⇩  
**欠損値を平均値で補完**    

それぞれについて、更に詳しく説明します。    

##### 特徴量の追加・削除
kaggleのkernelsの投稿を参考に、不要な特徴量の削除・特徴量の合成を行った。（下記リンクを参照）
<https://www.kaggle.com/nroman/features-correlations>

- 不要なカラムを削除
  以下カラムはラベルとの相関係数が極端に低いため、削除
  * UacLuaenable
  
  以下カラムは他の特徴量の中に相関係数が高いものがあるため、削除
  * Census_OSArchitecture
  * Census_OSSkuName
  * Census_OSUILocaleIdentifier
  * OsBuild
  
  以下カラムはinteractionがあるため、両方の値を連結した値を特徴量として追加し、元のカラムは削除  
  （例えば、Osverの値が同じ10.0.0.0だったとしても、Platformの値がwindows10の場合とwindows2016の場合とでmalware検出率が大きく異なる）
  * OsVer
  * Platform

| Osver    | Platform    | 全体の個数     | HasDetectionsが1である個数 | HasDetectionsが1である割合 |  
|:--------:|:-----------:|:------------:|:-------------------------:|:------------------------:|  
| 10.0.0.0 | windows10   | 8,618,174    |  4,309,331                | 0.500028                 |  
| 10.0.0.0 | windows2016 | 14,371       |  5,024                    | 0.349593                 |  
- 特徴量を合成
  * Osver\*Platform（理由は上記の通り）    
  

##### カラムの特性ごとの固有の処理
カラム毎にラベルとの相関係数が高くなるような処理を選別して実施（対象は数値変数）
  
- Census_OEMModelIdentifier  
⇨Noneを平均値で補完し、各値を1000で除算して四捨五入（その後ターゲットエンコーディング）

- Census_SystemVolumeTotalCapacity
⇨Noneを中央値で補完し、各値を10で除算して四捨五入（その後ターゲットエンコーディング）

- IsProtected
⇨Noneを0で補完

- Census_InternalBatteryType  
⇨lÿÿÿ, ÷ÿóöなどの、ターゲットエンコーディング時に支障が出そうな値は一律「z」に置換。  
　置換対象の値の選別基準は、以下の二項分布の両側検定を実施して帰無仮説を棄却する値以外とした。（Excelで作業）  
有意水準：5%  
帰無仮説：Census_InternalBatteryTypeが対象の値である行のmalware検出率(HasDetectionsが1である確率)が0.5  
対立仮説：Census_InternalBatteryTypeが対象の値である行のmalware検出率(HasDetectionsが1である確率)が0.5ではない  
  
帰無仮説に則って対象カラムの各値におけるmalwareの検出率がn=値の個数、p=0.5の二項分布に従うと仮定し、  
その確率密度関数に訓練データの実測値を当てはめた計算結果が0.05以上の場合、その値を「z」に置き換える。    


##### カテゴリカル変数の数値化  
数値ではない、文字列の変数を数値化するフェーズですが、今回は二種類の手法を用いました。  
一般的に知られている手法なのでそれぞれの説明は省略します。
- Ohe Hot Encoding  
  一意の値が10個以下のカラムに適用。
  「1. 前処理に用いる情報を作成」で取得したOne Hot Encoding後のカラム構造に沿うように調整する。
- Target Encoding  
　一意の値が11個以上のカラムに適用。
  「1. 前処理に用いる情報を作成」で作成した各カラムの各値と変換後の値を保有するdictionaryを使用する。


##### 欠損値を平均値で補完  
最後に、全て数値型となった訓練データの欠損値を平均値で補完する。      
「1. 前処理に用いる情報を作成」で算出した各カラムの前処理後の平均値を使用する。  


#### 3. 訓練データをモデルにfit  
前処理済みのデータをモデルにfitしていく。
一度に900万件近くもの訓練データをfitすることになるため、メモリエラーを避けるため
オンライン学習ができるxgboostを採用。
更に進捗をまめに把握するため、5000件ずつfitするコードを書いた。 
fitの度にモデルを保存（更新）し、最終的に全件fitできるようにする。


#### 4. テストデータを前処理  
テストデータをロードし、predictできるよう前処理を施す。  
内容は「2. 訓練データを前処理」と同じ。

#### 5. テストデータをpredict  
訓練したモデルで、前処理済みのデータのラベルを予測する。    


### 上位ランカーのコードと自分のコードの比較
比較的上位にランクインし、特に参考になった下記リンクのコードをローカルで実行して読み解き、自分のコードと比較しました。
<https://www.kaggle.com/bogorodvo/lightgbm-baseline-model-using-sparse-matrix>  

#### 上位ランカーのコードの処理フロー  
以下の順で処理していた。  
1. 訓練・テストデータのcsvを全件pandasのDataFrameで読み込み
2. 訓練・テストデータの全カラム（数値変数含む）をlabel encoding
3. 訓練・テストデータの全カラムに対して、以下の値を抽出  
   ・訓練データに1000個以上観測された値
   ・観測された個数のうち訓練データに含まれる値が2割より大きい且つ8割未満の（訓練データ・テストデータ間で偏りのない）値。  
4. 訓練・テストデータの全カラムに対して、上記3の手順で抽出した値以外を0に置換
5. 訓練・テストデータの全カラムに対してOne Hot Encodingを実施し、同時にSparse Matrix（疎行列）に変換
6. 訓練・テストデータをcsr_matrixに変換し、StratifiedKFoldにより5回に分けて交差検証・テストデータをpredict
7. 上記6の手順で出力した予測値のそれぞれの行で平均をとり、csvファイルとして出力

#### 上位ランカーのコードの特筆すべき（自分のコードにはなかった）点  
- 訓練・テストデータのcsvをDataFrameとして読み込むとき、  
  全てのカラムに対して一つ一つデータ型を指定する   
  ⇨これにより、数百万件規模のデータを難なくDataFrameとしてメモリに格納できていた。  
   これはkaggleのKernelsをよく見るとほとんどの人がやっていたが、  
   自分は全てのカラムをnp.float64の非常にメモリを消費するデータ型で読み込んでおり、  
   そのせいでデータの読み込みすらchunksiseを指定して分割するしかなかった。  
   愚の骨頂。    
   
- 訓練データ内で観測数の少ないデータをNullとして扱う  
  ⇨観測数が極端に少ないと、ラベルが1である確率が母集団のそれと乖離する可能性が高いため。  
   （target encodingのsmoothingと同じ理由）  
   コード中では1000を基準としていた。

- 訓練データに多いがテストデータには少ない、又はその逆の値をNullとして扱う  
  ⇨テストデータの予測精度に大きく影響するため、重要な処理と思われる。
  
- One Hot Encoding時にsparse_matrix、学習時にcsr_matrixに変換し、メモリ消費を抑える  
  ⇨これにより全データの全カラムに対してOne Hot Encodingを実施することができ、  
   target encodingによるリークに悩まされる必要が無くなる。  
   また、全件同時にfit・predictすることも可能になるため、  
   自分のコードのように逐一分割する必要もなくなる。  
  
- StratifiedKFoldにより5回に分けて交差検証し、予測値の平均をとる  
  ⇨交差検証にStratifiedKFoldを使っているのは勉強になった。  
   validate用データのラベルの値の分布が均一になるように分割してくれるらしい。  
   一方自分のコードではたった一度のfit・predictにすら数時間かかったため、交差検証はできていなかった。  
   致命的な欠陥であるため、今後は優先的に交差検証をコードに組み込むようにしたい。  

#### 自分のコードの方が良いと思った点  
- 数値変数は数値変数のまま処理していたこと  
  上位ランカーのコードでは数値変数も全てカテゴリ変数と同様  
  Label Encoding ⇨ 観測数の少ないデータ・偏りのあるデータを削除 ⇨ One Hot Encoding  
  の流れで処理していた。  
  ラベルと線形相関があるような数値変数に対しても上記のような処理を行うと、  
  ほとんどの値が「観測数の少ないデータ・偏りのあるデータ」として削除されて情報損失が起こりかねないため、
  多くの人がやっているように数値変数は数値変数として扱う方が良い場合もあるのではないかと思った。    
  
### 課題と対策  
以下の課題と対策については以下の図の通りです。
本当は山ほどありますが、特に重要だと判断したものだけをかいつまんで記載しました。
